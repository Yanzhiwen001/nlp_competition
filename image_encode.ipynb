{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from PIL import Image\n",
    "import io\n",
    "import urllib\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "#import other packages for dataset store\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d6533c8cfe3effc0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Zhiwen Yan/.cache/huggingface/datasets/csv/default-d6533c8cfe3effc0/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cca929ed33b4a60ac6d6be083d7e960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897993e78a984b668994aae482914b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953306ed40040a8b01cbd3558cb9ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Zhiwen Yan/.cache/huggingface/datasets/csv/default-d6533c8cfe3effc0/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941ade0b7a9b47f9938a43e10668d23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_dataset('csv', data_files='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'ImageURL', 'ISO639-3'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test data based on hau, tha, kir\n",
    "total_test = pd.read_csv(\"test.csv\")\n",
    "test_hau = total_test[total_test['ISO639-3']=='hau']\n",
    "test_tha = total_test[total_test['ISO639-3']=='tha']\n",
    "test_kir = total_test[total_test['ISO639-3']=='kir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function fetch_images at 0x0000026CE28FC168> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e5954dc8c34423bdf505fd83746862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#actual download image from url\n",
    "USER_AGENT = get_datasets_user_agent()\n",
    "\n",
    "def fetch_single_image(image_url, timeout=None, retries=0):\n",
    "    request = urllib.request.Request(\n",
    "        image_url,\n",
    "        data=None,\n",
    "        headers={\"user-agent\": USER_AGENT},\n",
    "    )\n",
    "    with urllib.request.urlopen(request, timeout=timeout) as req:\n",
    "        if 'png' in image_url:\n",
    "          png = Image.open(io.BytesIO(req.read())).convert('RGBA')\n",
    "          png.load() # required for png.split()\n",
    "          background = Image.new(\"RGB\", png.size, (255, 255, 255))\n",
    "          background.paste(png, mask=png.split()[3]) # 3 is the alpha channel\n",
    "          image_id = str(uuid.uuid4()) # confused about image_id here?\n",
    "          image_path = \"images_test/\" + image_id + \".jpg\"\n",
    "          background.save(image_path, 'JPEG', quality=80)\n",
    "        else:\n",
    "          image = Image.open(io.BytesIO(req.read()))\n",
    "          image_id = str(uuid.uuid4())\n",
    "          image_path = \"images_test/\" + image_id + \".jpg\"\n",
    "          image.save(image_path)\n",
    "    return image_path\n",
    "\n",
    "def fetch_images(batch, num_threads, timeout=None, retries=3):\n",
    "    fetch_single_image_with_args = partial(fetch_single_image, timeout=timeout, retries=retries)\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        batch[\"image_path\"] = list(executor.map(fetch_single_image_with_args, batch[\"ImageURL\"]))\n",
    "    return batch\n",
    "\n",
    "num_threads = 20\n",
    "test_dataset = test_dataset.map(fetch_images, batched=True, batch_size=100, fn_kwargs={\"num_threads\": num_threads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset to local\n",
    "test_dataset.save_to_disk(\"dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload dataset\n",
    "test_dataset = load_from_disk(\"dataset_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11ec100023c0832803804b166c9e313587998d7e80407ebd90b9748988d89aaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

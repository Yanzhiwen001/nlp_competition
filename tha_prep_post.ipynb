{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import other packages for dataset store\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"dataset_tha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story', 'image_path'],\n",
       "        num_rows: 58\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story', 'image_path'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story', 'image_path'],\n",
       "        num_rows: 2913\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pythainlp\n",
    "pythainlp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default (newmm):\n",
      "['เจ้า', 'กระต่าย', 'กระโดด', 'ผ่าน', 'มา', '\\xa0', ' ', 'มัน', 'หวัง', 'ว่า', 'จะ', 'ได้', 'กิน', 'กล้วย', '0', 'สีเทา', ' ', 'จึง', 'พูด', 'ขึ้น', 'ว่า', ' ', '“', 'เจ้า', 'กระต่าย', 'จ๋า', '\\xa0', ' ', 'อีก', 'สาม', 'อาทิตย์', '”', '0', 'เจ้า', 'กระต่าย', 'จึง', 'กระโดด', 'ผ่าน', 'ไป']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'เจ้า กระต่าย กระโดด ผ่าน มา \\xa0 0 มัน หวัง ว่า จะ ได้ กิน กล้วย 0 สีเทา 0 จึง พูด ขึ้น ว่า 0 “ เจ้า กระต่าย จ๋า \\xa0 0 อีก สาม อาทิตย์ ” 0 เจ้า กระต่าย จึง กระโดด ผ่าน ไป'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import word_tokenize\n",
    "\n",
    "#test\n",
    "text = \"เจ้ากระต่ายกระโดดผ่านมา\\xa0 มันหวังว่าจะได้กินกล้วย\\nสีเทา จึงพูดขึ้นว่า “เจ้ากระต่ายจ๋า\\xa0 อีกสามอาทิตย์”\\nเจ้ากระต่ายจึงกระโดดผ่านไป\"\n",
    "text = text.replace('\\n', '0')\n",
    "\n",
    "print(\"default (newmm):\")\n",
    "print(word_tokenize(text)) #list\n",
    "\n",
    "newcaption = word_tokenize(text)\n",
    "newcaption = list([x if x is not \" \" else \"0\" for x in newcaption])\n",
    "newcaption = ' '.join(newcaption)\n",
    "newcaption\n",
    "#for i in range(len(newcaption)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d80908ca004672972b867e37b838a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e0e2bfa6854cf6b6e5bb4aeb12e085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dffcbe3e0f4595bc24fcf776597b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from pythainlp import word_tokenize\n",
    "\n",
    "def single_token(text):\n",
    "    #replace \\n by 0, because we need to record where \\n appeared\n",
    "    text = text.replace('\\n', '0')\n",
    "    #use thai word tokenizer\n",
    "    caption2 = word_tokenize(text)\n",
    "    caption2 = list([x if x is not \" \" else \"0\" for x in caption2])\n",
    "    result = ' '.join(caption2)\n",
    "    return result\n",
    "\n",
    "def fetch_caption(batch, num_threads, timeout=None, retries=3):\n",
    "    fetch_single_image_with_args = partial(single_token)\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        batch[\"caption2\"] = list(executor.map(fetch_single_image_with_args, batch[\"caption\"]))\n",
    "    return batch\n",
    "\n",
    "num_threads = 20\n",
    "dataset = dataset.map(fetch_caption, batched=True, batch_size=100, fn_kwargs={\"num_threads\": num_threads})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': '723f3568-0f5c-43b0-9198-e6afa2c81f5d',\n",
       " 'image_url': 'https://bloom-vist.s3.amazonaws.com/%EF%BB%BF%E0%B8%9E%E0%B8%A2%E0%B8%B1%E0%B8%8D%E0%B8%8A%E0%B8%99%E0%B8%B0%E0%B8%A7%E0%B8%B8%E0%B9%88%E0%B8%99%E0%B8%A7%E0%B8%B2%E0%B8%A2+%E0%B8%81%E0%B8%B1%E0%B8%9A+%E0%B8%AA%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%89%E0%B8%A2%E0%B8%8A%E0%B8%B2/1.10.jpg',\n",
       " 'caption': 'พยัญชนะก.ไก่ รีบเข้ามากอดและพูดขอบคุณสระอา ที่เข้ามาช่วยจากนั้นก็ขอโทษสระอา ที่ตนทอดทิ้งเพื่อนรักให้เดินทางมาเพียงลำพัง สระอารับคำขอโทษจากพยัญชนะก.ไก่ แล้วทั้งสองเดินเที่ยวงานกันอย่างสนุกสนาน และพากันกลับอณาจักรสมุดหรรษาอย่างมีควาสุข',\n",
       " 'story_id': 'f4a9150f-3b0f-491d-8869-4067726f269b',\n",
       " 'album_id': 'ad14aeaa-c939-4885-8a10-46fbc5b73bc9',\n",
       " 'license': 'cc-by-nc-nd',\n",
       " 'original_bloom_language_tag': 'th',\n",
       " 'index_in_story': 9,\n",
       " 'image_path': 'images_tha/517b11e0-8bab-427f-a9bb-fbb97777ad04.jpg',\n",
       " 'caption2': 'พยัญชนะ ก. ไก่ 0 รีบ เข้ามา กอด และ พูด ขอบคุณ สระ อา 0 ที่ เข้ามา ช่วย จากนั้น ก็ ขอโทษ สระ อา 0 ที่ ตน ทอดทิ้ง เพื่อนรัก ให้ เดินทาง มา เพียงลำพัง 0 สระ อา รับ คำขอโทษ จาก พยัญชนะ ก. ไก่ 0 แล้ว ทั้งสอง เดิน เที่ยวงาน กัน อย่าง สนุกสนาน 0 และ พา กัน กลับ อณา จักร สมุด หรรษา อย่าง มี ค วา สุข'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset to local\n",
    "dataset.save_to_disk(\"dataset_tha2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'เจ้ากระต่ายกระโดดผ่านมา\\xa0 มันหวังว่าจะได้กินกล้วยสีเทา จึงพูดขึ้นว่า “เจ้ากระต่ายจ๋า\\xa0 อีกสามอาทิตย์”เจ้ากระต่ายจึงกระโดดผ่านไป'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"เจ้ากระต่ายกระโดดผ่านมา\\xa0 มันหวังว่าจะได้กินกล้วย\\nสีเทา จึงพูดขึ้นว่า “เจ้ากระต่ายจ๋า\\xa0 อีกสามอาทิตย์”\\nเจ้ากระต่ายจึงกระโดดผ่านไป\"\n",
    "text = text.replace(r\"!\\\"#$%&\\(\\)\\*\\+.,-/:;=?@\\[\\\\\\]^_`{|}~\", \"\")\n",
    "text = text.replace('\\n', '')\n",
    "#text = text.replace('\\xa0', '')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post process of predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import other packages for dataset store\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tha_result = pd.read_csv(\"tha_result_50.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pred_column = tha_result['predicted'].tolist()\n",
    "\n",
    "post_pred_column = []\n",
    "for i in range(len(list_of_pred_column)):\n",
    "    text = list_of_pred_column[i]\n",
    "    text = text.replace('\\xa0', '')\n",
    "    text = \"\".join(text.split())\n",
    "    text = text.replace('0', ' ')\n",
    "    for j in text:\n",
    "        if j == \"\":\n",
    "            text.remove(j)\n",
    "    \n",
    "    post_pred_column.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tha_result['predicted']\n",
    "tha_result.insert(1, 'predicted2', post_pred_column, allow_duplicates=False)\n",
    "tha_result.to_csv(\"tha_result3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tha_result3.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(tha_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "see = pd.read_csv(\"tha_result3.csv\", encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11ec100023c0832803804b166c9e313587998d7e80407ebd90b9748988d89aaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
